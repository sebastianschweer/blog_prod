<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Emacs on Sastibe&#39;s Data Science Blog</title>
    <link>http://www.sastibe.de/categories/emacs/</link>
    <description>Recent content in Emacs on Sastibe&#39;s Data Science Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jul 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="http://www.sastibe.de/categories/emacs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Registering my Blog at the VG Wort</title>
      <link>http://www.sastibe.de/2018/07/registering-my-blog-at-the-vg-wort/</link>
      <pubDate>Tue, 17 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.sastibe.de/2018/07/registering-my-blog-at-the-vg-wort/</guid>
      <description>Suddenly, Attention So, it seems like my blog is getting some attention. Recently, I was even featured on the front page of Hacker News:
Number 17... only 16 more to go!

Obviously, I am delighted and flattered by the number of people reading and discussing my blog. But since we&#39;re living in a material world, and I am a material guy, I kept on wondering &#34;is there any way to monetize this in an ethical way?&#34;. Obviously, advertisements are out of the question, but are there other ways?
VG Wort The VG Wort, or Verwertungsgesellschaft Wort is a German association tasked with collecting and distributing profits made secondary exploitation rights of original textual contents. Essentially, it tries to reimburse authors and journalists for the money they &#34;lose&#34; by texts that are copied or digitally reproduced and thus &#34;free of charge&#34;. The money received by the VG Wort stems mostly from so ca lled Kopierabgabegeräten 1.
A Step-by-Step Guide for registering your Blog at VG Wort In what follows, I recount the steps I needed to take to register my first blog post in VG Wort. Note that all of these steps are exclusively available to German citizens, which is unfortunate: An internanationally available solution like the one provided by VG Wort for &#34;making money on the internet without resorting to ads&#34; could have beneficial consequences for everyone. But I digress...
Registering an account New authors nedd to first register an account, this can be done here. I already had my account set up for my scientific papers.
Registering a blog post  The first informational page on how to register a blog post is given here. It states the following preliminaries have to be met: The blog post has to contain at least 1800 characters (including whitespaces) There my be no copy-restriction on the resulting file (DRM) The text was read by a certain number of people, counted by a VG Wort tracking pixel, or &#34;Zählmarke&#34;  Obtaining the Zählmarken is straightforward: In my VG Wort Account for the &#34;registration of texts online&#34;, or Texte online melden, i.e. T.O.M. in German, I was able to order 100 Zählmarken as a somewhat weirdly formatted csv:
Nevermind the encoding problems... but repeating the header for each line? C&#39;mon!

Keeping Track of the Zählmarken Seeing the poorly formatted csv made me realize I needed to keep track of my Marken in a more sensible way. So I came up with the following (dummy) org-table:
   Filename Zaehlmarke No. Public Key Private Key Post URL No. Characters     vgwort_1.csv 1 &#34;http://vg09.met.vgwort.de/na/foo&#34; bar 2018-01-27-setting-up-a-scalable-rstudio-instance-in-aws.html 12200    Counting the number of characters in all the blog posts using hugo My blog is written in hugo, I&#39;m using the Tranquilpeak theme to be precise. Even though I write most of my articles in org-mode nowadays, there&#39;s still quite a lot of HTML clutter in my source files. How to count the characters excluding such &#34;meta-characters&#34;?
My solution is a bit indirect, but it works quite well. For my RSS feed, I customized the template rss.xml in order to read
... {{ with .Site.Author.email }}&amp;lt;author&amp;gt;{{.}}{{ with $.Site.Author.name }} ({{.}}){{end}}&amp;lt;/author&amp;gt;{{end}} &amp;lt;guid&amp;gt;{{ .Permalink }}&amp;lt;/guid&amp;gt; &amp;lt;description&amp;gt;{{ .Content | html }}&amp;lt;/description&amp;gt; ...  The small alteration of using .Content instead of the default .Summary is, that my feed contains &#34;full content&#34;, i.e. the entire post. In order to count the characters in all of my posts, however, I alter the respective line to read
... {{ with .Site.Author.email }}&amp;lt;author&amp;gt;{{.}}{{ with $.Site.Author.name }} ({{.}}){{end}}&amp;lt;/author&amp;gt;{{end}} &amp;lt;guid&amp;gt;{{ .Permalink }}&amp;lt;/guid&amp;gt; &amp;lt;description&amp;gt;{{ .Plain | html }}&amp;lt;/description&amp;gt; ...  hugo uses .Plain to wipe away all HTML parts of the content. Hence, I can build my blog locally, open the resulting index.xml in emacs (obviously) and run M-= on the post.
How much money is in it, though? As for this question, I have no answer yet. As of the publishing of this post, I have implemented the Zählmarken in all of the posts, corrected the Datenschutzerklärung (again, obviously) and am now waiting for results. If I understand the process correctly, I will have news by July next year. So, let&#39;s see, eh?
Footnotes  I love the German language. It seems like no word can be considered official enough for law texts unless it has at least 5 syllables. [return]   </description>
    </item>
    
    <item>
      <title>It&#39;s here: Org Agenda for the World Cup 2018</title>
      <link>http://www.sastibe.de/2018/06/its-here-org-agenda-for-the-world-cup-2018/</link>
      <pubDate>Tue, 05 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.sastibe.de/2018/06/its-here-org-agenda-for-the-world-cup-2018/</guid>
      <description>As I recently pointed out, I have grown rather fond of Emacs and org-mode especially in recent months. On an entirely unrelated note, the FIFA world cup is right around the corner. Wouldn&#39;t it be nice to combine my passion for the greatest sport in the world (even including all the inevitable diving, arguing with the referees etc...) with my new-found passion for clear and concise org-agendas?
Just so...

A short Google research lead to these two GitHub repositories for the Euro 2012 and the World Cup 2014. As I couldn&#39;t find anything similar for the World Cup 2018, I decided to create it myself.
Here is the result
The content of the schedule is as accurate as I could manage: I read the contents of the raw data into the desired org format via regex (in Emacs, obviously) and manually checked the results against the entries on the wiki page. Writing the regex was actually ... rather fun? A bit weird since it wasn&#39;t pretty, let me show you the first few symbols:
replace-regexp &amp;lt;RET&amp;gt; |\s-+\([0-9]\{1,2\}\) |\([^|]+....  Anyways, it worked, and the result is anyone&#39;s to enjoy. For the record, let me state clearly that I Do Not Intend To Update The Scores In The Repository in any timely fashion. If I get to it, I will, but let&#39;s see.
</description>
    </item>
    
    <item>
      <title>Use Emacs Org Mode and REST APIs for an up-to-date Stock Portfolio</title>
      <link>http://www.sastibe.de/2018/05/2018-05-11-emacs-org-mode-rest-apis-stocks/</link>
      <pubDate>Fri, 11 May 2018 23:13:13 +0200</pubDate>
      
      <guid>http://www.sastibe.de/2018/05/2018-05-11-emacs-org-mode-rest-apis-stocks/</guid>
      <description>A couple of weeks ago, I started to work with Emacs, and I grow fonder of it every day. During a very short time period, it has become my go-to editor for nearly everything I do on my computer, including (but not limited to)
 planning my Todos (in org-mode, to be precise), setting up my agenda (org-mode again), taking memos during meetings writing my (longer) e-mails play around with new stuff write blog posts (this is the first of these...)  It is difficult to pin down exactly why Emacs is taking over so much. My main influences for starting with EMACS were blogposts, the first describing a general EMACS setup, the second detailing how to implement GTD, i.e. Getting Things Done in Emacs org-mode.
In this post, I will demonsrate the strengths of using Emacs in a very specific use case: Getting up-to-date financial data to use in a spread-sheet including all your financial data. Applications like these are usually provided by online banks themselves, so that I don&#39;t show you anything particularly new or shiny. However, the ability to customize every step of the way brings with a number of advantages.
Finding a REST API for Stock Quotes First, we need to get up-to-date financial data from a REST API. I decided to use Alpha Vantage, a site I first stumbled upon after reading this blog post. The other APIs listed on that page had various issues, either being deprecated in the near future (google, yahoo, stooq) or not having a number of symbols (IEX). The API of Alphavantage is rather easy to understand, even though the naming convention is terrible. Try for instance this link using the demo API key, yielding the following result for the Microsoft stock:
{ &amp;quot;Meta Data&amp;quot;: { &amp;quot;1. Information&amp;quot;: &amp;quot;Intraday (1min) prices and volumes&amp;quot;, &amp;quot;2. Symbol&amp;quot;: &amp;quot;MSFT&amp;quot;, &amp;quot;3. Last Refreshed&amp;quot;: &amp;quot;2018-05-11 16:00:00&amp;quot;, &amp;quot;4. Interval&amp;quot;: &amp;quot;1min&amp;quot;, &amp;quot;5. Output Size&amp;quot;: &amp;quot;Compact&amp;quot;, &amp;quot;6. Time Zone&amp;quot;: &amp;quot;US/Eastern&amp;quot; }, &amp;quot;Time Series (1min)&amp;quot;: { &amp;quot;2018-05-11 16:00:00&amp;quot;: { &amp;quot;1. open&amp;quot;: &amp;quot;97.5900&amp;quot;, &amp;quot;2. high&amp;quot;: &amp;quot;97.7300&amp;quot;, &amp;quot;3. low&amp;quot;: &amp;quot;97.5750&amp;quot;, &amp;quot;4. close&amp;quot;: &amp;quot;97.7000&amp;quot;, &amp;quot;5. volume&amp;quot;: &amp;quot;3776187&amp;quot; }, &amp;quot;2018-05-11 15:59:00&amp;quot;: { &amp;quot;1. open&amp;quot;: &amp;quot;97.4800&amp;quot;, &amp;quot;2. high&amp;quot;: &amp;quot;97.5900&amp;quot;, &amp;quot;3. low&amp;quot;: &amp;quot;97.4700&amp;quot;, &amp;quot;4. close&amp;quot;: &amp;quot;97.5900&amp;quot;, &amp;quot;5. volume&amp;quot;: &amp;quot;257615&amp;quot; },...  Reading API Requests into Emacs Variables Having located the data out in the internet was a good first step, but now we need to figure out a way how to use this information. Luckily, most of the work needed for this can be found in various places on the net, for instance in this blog post. I decided to follow their general setup, using the following packages:
 org org-babel request json  The API used in their scenario gave different results with a much cleaner nomenclature. For the Alphavantage API, I had to become a little creative with the eLisp code.
(require &#39;request) (require &#39;json) (require &#39;cl) (request &amp;quot;https://www.alphavantage.co/query&amp;quot; :params `((&amp;quot;function&amp;quot; . &amp;quot;TIME_SERIES_INTRADAY&amp;quot;) (&amp;quot;symbol&amp;quot; . &amp;quot;SC0J&amp;quot;) (&amp;quot;interval&amp;quot; . &amp;quot;1min&amp;quot;) (&amp;quot;apikey&amp;quot; . &amp;quot;...&amp;quot;)) :parser &#39;json-read :success (function* (lambda (&amp;amp;key data &amp;amp;allow-other-keys) (setq open_sc0j (string-to-number (cdr (elt (elt (elt data 1) 1) 1)))))))  The variable open_sc0j is evaluated as follows: From the received json, take the second entry of the second element of the second element. Not very nice, but it works...
I encountered a second difficulty in my portfolio: I have both European stocks (in EUR) and American stocks (traded in USD). In order to keep my balances comparable, I added yet another variable rate_usd_eur, which receives up-to-date exchange rates from USD to EUR from the appropriate query. All in all, my requests to Alphavantage look like this:
(request &amp;quot;https://www.alphavantage.co/query&amp;quot; :params `((&amp;quot;function&amp;quot; . &amp;quot;TIME_SERIES_INTRADAY&amp;quot;) (&amp;quot;symbol&amp;quot; . &amp;quot;SC0J&amp;quot;) (&amp;quot;interval&amp;quot; . &amp;quot;1min&amp;quot;) (&amp;quot;apikey&amp;quot; . &amp;quot;...&amp;quot;)) :parser &#39;json-read :success (function* (lambda (&amp;amp;key data &amp;amp;allow-other-keys) (setq open_sc0j (string-to-number (cdr (elt (elt (elt data 1) 1) 1))))))) (request &amp;quot;https://www.alphavantage.co/query&amp;quot; :params `((&amp;quot;function&amp;quot; . &amp;quot;CURRENCY_EXCHANGE_RATE&amp;quot;) (&amp;quot;from_currency&amp;quot; . &amp;quot;USD&amp;quot;) (&amp;quot;to_currency&amp;quot; . &amp;quot;EUR&amp;quot;) (&amp;quot;apikey&amp;quot; . &amp;quot;...&amp;quot;)) :parser &#39;json-read :success (function* (lambda (&amp;amp;key data &amp;amp;allow-other-keys) (setq rate_usd_eur (string-to-number (cdr (elt (elt data 0) 5))))))) (request &amp;quot;https://www.alphavantage.co/query&amp;quot; :params `((&amp;quot;function&amp;quot; . &amp;quot;TIME_SERIES_INTRADAY&amp;quot;) (&amp;quot;symbol&amp;quot; . &amp;quot;PG&amp;quot;) (&amp;quot;interval&amp;quot; . &amp;quot;1min&amp;quot;) (&amp;quot;apikey&amp;quot; . &amp;quot;...&amp;quot;)) :parser &#39;json-read :success (function* (lambda (&amp;amp;key data &amp;amp;allow-other-keys) (org-table-iterate-buffer-tables) (setq open_prg (* rate_usd_eur (string-to-number (cdr (elt (elt (elt data 1) 1) 1))))))))  Putting this code inside an org-mode file, bracketing it by code blocks #+BEGIN_SRC emacs-lisp :results none and #+END_SRC, and hitting &#34;C-c C-c&#34; inside it leads to the evaluation of the code block and thus the filling of the variables open_sc0j, rate_usd_eur and open_prg. Since we included the wonderful little function org-table-iterate-buffer-tables, the evaluation also repeats until all the columns in the table below are calculated correctly. This neat little trick I also copied from here.
Setting up a Custom Stock Portfolio Org Table After these steps, we now set up an org-table to give us a customizable overview of how our stocks are doing. That means setting up an org-table with columns for historic data, such as the date of the buy. Additionally, we use the #+TBLFM function to calculate appropriate performance indicators. An example for such functions:
| Stock | Symbol | Amt. | Buy | Date Bought | Fees | Dividends | Close | Gain | Gain Perc | Gain per Day | |---------------+--------+------+--------+-----------------+-------+-----------+-------+--------+-----------+--------------| | MSCI ETF | SC0J | 10 | 47.11 | [2018-04-16 Mo] | 12.35 | 0 | | | | | | ProcterGamble | PG | 5 | 65.014 | [2015-10-01 Do] | 10.61 | 72.03 | | | | | #+TBLFM: $9=(-$4 + $8)*$3 - $6 + $7;%0.3f::$10=100*$9/($4*$3)::$11=$9/(now() - $5)::@2$8=&#39;(format &amp;quot;%f&amp;quot; open_sc0j)::@3$7=17.78 + 17.70 + 17.94 + 18.61::@3$8=&#39;(format &amp;quot;%f&amp;quot; open_prg)  This code leads to the following result:
   Stock Symbol Amt. Buy Date Bought Fees Dividends Close Gain Gain Perc Gain per Day     MSCI ETF SC0J 10 47.11 [2018-04-16 Mo] 12.35 0 49.290000 9.450 2.0059435 0.35552367   ProcterGamble PG 5 65.014 [2015-10-01 Do] 10.61 72.03 61.342605 43.063 13.247301 0.045111962    In this example, Gain is first calculated by multiplying -$4 + $8, i.e. the difference between Buy and (today&#39;s) Close by the amount of stocks bought. Additionally, any dividends are added and any fees are subtracted, yielding a &#34;net gain&#34; for the stock. In column Gain per Day, this number is broken down per day since I bought the stock, highlighting my most efficient assets.
There is no limit to what types of functions one can use, and no limit on the sophistication of analysis. And all of this within a very light-weight, easy-to-use interface, without any unnecessary over-head. It is not only convenient, but also educational: while writing this article, I learned a lot about REST APIs and financial data.
Let me conclude this article by picking up a picture from one of the blog posts that got me into Emacs in the first place: Emacs is like a classical steel frame road bike, reliant, robust, nothing fancy but easy to repair. It is the ideal tool to explore the wilderness of the internet. And I can only invite everybody else to come along for the ride.
</description>
    </item>
    
  </channel>
</rss>
